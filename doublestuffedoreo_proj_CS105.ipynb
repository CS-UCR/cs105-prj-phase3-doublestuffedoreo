{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24fRMKkZgc1_"
   },
   "source": [
    "Sandy Tsan, 861299012\n",
    "\n",
    "Douglas Tran, 861208900\n",
    "\n",
    "# Riverside Crime Reports and the Riverside Yelp Restaurants\n",
    "### Part 1: Dataset info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'Crime_Reports.csv' does not exist: b'Crime_Reports.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-08a3faf41015>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcrimes_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Crime_Reports.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mcrimes_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrimes_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"offenseDate\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"crimeType\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"premise\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"blockAddress\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"npc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcrimes_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'offenseDate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'Crime_Reports.csv' does not exist: b'Crime_Reports.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "crimes_df = pd.read_csv(\"Crime_Reports.csv\")\n",
    "crimes_df = crimes_df[[\"offenseDate\",\"crimeType\",\"premise\",\"blockAddress\",\"npc\"]].copy()\n",
    "crimes_df['offenseDate'].replace('', np.nan, inplace=True)\n",
    "crimes_df = crimes_df.dropna(subset=['offenseDate'])\n",
    "\n",
    "restaurants_df = pd.read_csv('Yelp/restaurants.csv')\n",
    "restaurants_df = restaurants_df.replace(np.nan, 0.0, regex=True)\n",
    "restaurants_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_dir_yelp = \"\"\n",
    "yelp_df = pd.read_csv(\"Yelp/restaurants.csv\")\n",
    "yelp_df.iat[398, 7] = 0\n",
    "yelp_df['zip_code'] = yelp_df['zip_code'].astype(int)\n",
    "yelp_df['price'] = yelp_df['price'].fillna(\"$NO\")\n",
    "prices = {'$': 1, '$$': 2, '$$$': 3, '$$$$': 4, '$NO': 0}\n",
    "yelp_df.price = [prices[item] for item in yelp_df.price]\n",
    "yelp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24fRMKkZgc1_"
   },
   "source": [
    "### Part 2: Building a model\n",
    "This can include building a model to perform prediction (like applying linear regression or kNN) or clustering. \n",
    "\n",
    "You can also use the models for data analysis, not just ‘predictions’. For example, in linear regression we saw that the\n",
    "resulting coefficients tell us how the features are correlated to the target variable. \n",
    "\n",
    "So, this analysis might help you identify features of importance with respect to a target feature in the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_train = yelp_df.loc[:275].copy()\n",
    "yelp_test = yelp_df.loc[276:].copy()\n",
    "yelp_train.plot.scatter(x=\"zip_code\",y=\"review_count\")\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train = yelp_train[[\"zip_code\"]]\n",
    "X_test = yelp_test[[\"zip_code\"]]\n",
    "y_train = yelp_train[\"review_count\"]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X=X_train, y=y_train)\n",
    "model.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_new = pd.DataFrame()\n",
    "X_new[\"zip_code\"] = np.linspace(0, 20000, num=50)\n",
    "y_new_ = pd.Series(\n",
    "            model.predict(X_new),\n",
    "            index=X_new[\"zip_code\"]\n",
    ")\n",
    "\n",
    "print(\"Coefficient: \", model.coef_)\n",
    "print(\"Intercept: \", model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform predictions based on numerical values from the Yelp dataset, that is, the zip codes, review counts, ratings, and prices. This chart shows the average zip code in comparison to the review count.\n",
    "\n",
    "The data does not necessarily need an intercept line for the linear regression in this case.\n",
    "\n",
    "As a pre-part 3 analysis, we can see that the density is in the 92500 zip code range, so it's safe to say a lot of reviews are close to UCR campus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24fRMKkZgc1_"
   },
   "source": [
    "## Part 3: Data analysis\n",
    "\n",
    "We are looking to see the following:\n",
    "1. Do the quality of the restaurants (as weighted by its price and ratings) affect the crime rate of a certain zone?\n",
    "2. Do restaurants tend to congregate around a certain zone? Is that congregation somewhat due to the amount of crime in that zone?\n",
    "\n",
    "We hypothesize that higher rated and higher priced restaurants have lower crime rates. We also hypothesize that restaurants tend to congregate around zones that have lower crime rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants_df = restaurants_df[(restaurants_df.zip_code != '09251') | (restaurants_df.zip_code != '91010') | (restaurants_df.zip_code != 'GL54 2DP')]\n",
    "restaurants_df[\"npc_zones\"] = restaurants_df[\"zip_code\"].map({\n",
    "    '92509' : 'WEST',\n",
    "    '92507' : 'EAST',\n",
    "    '92503' : 'CENTRAL',\n",
    "    '92506' : 'CENTRAL',\n",
    "    '92505' : 'WEST',\n",
    "    '92504' : 'NORTH',\n",
    "    '92501' : 'EAST',\n",
    "    '92508' : 'CENTRAL',\n",
    "    '92313' : 'NORTH',\n",
    "    '92502' : 'EAST',\n",
    "    '92516' : 'EAST',\n",
    "    '92882' : 'WEST',\n",
    "    '92324' : 'NORTH',\n",
    "    '92373' : 'EAST',\n",
    "    '92521' : 'EAST',\n",
    "    '92345' : 'NORTH'\n",
    "})\n",
    "\n",
    "restaurants_df[\"price_value\"] = restaurants_df[\"price\"].map({\n",
    "    '0.0' : 0,\n",
    "    '$' : 1,\n",
    "    '$$' : 2,\n",
    "    '$$$' : 3,\n",
    "    '$$$$' : 4,\n",
    "})\n",
    "\n",
    "restaurants_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24fRMKkZgc1_"
   },
   "source": [
    "In the command above, we remove the unlikely zipcodes from the yelp dataset (ones that are invalid and ones that don't correspond to Riverside county). We then remap these zipcodes to match the zones with the crime database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_df = crimes_df[(crimes_df.npc == 'NORTH') | (crimes_df.npc == 'CENTRAL') | (crimes_df.npc == 'WEST') | (crimes_df.npc == 'EAST')]\n",
    "crimes_df.npc.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24fRMKkZgc1_"
   },
   "source": [
    "In the command above, we remove the invalid zones including the unknown. Removal is possible as these extraneous zones make up less than 5% of the dataset we are given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_df.npc.value_counts().plot.bar(legend=True)\n",
    "\n",
    "crimes_df[crimes_df.npc == \"NORTH\"].describe()\n",
    "crimes_df[crimes_df.npc == \"CENTRAL\"].describe()\n",
    "crimes_df[crimes_df.npc == \"WEST\"].describe()\n",
    "crimes_df[crimes_df.npc == \"EAST\"].describe()\n",
    "\n",
    "print( \"West crime =\", 42101/2075, \"crimes per day \\nNorth crime =\", 41774/2039, \"crimes per day \\nEast crime =\", 39270/2050, \"crimes per day \\nCentral crime =\", 31421/2013, \"crimes per day \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24fRMKkZgc1_"
   },
   "source": [
    "Here, we are finding the amount of crime per day. So we are arregating the total number of unique crimes per day and then dividing that number under the total number of crimes in that zone. From this, we can see that the central zone has less occurences of crime per day than other zones, which correlates to the graph showing the total amount of crime in that area. This is our crime rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants_df.npc_zones.value_counts().plot.bar(legend=True, color=\"#2ecc71\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24fRMKkZgc1_"
   },
   "source": [
    "Here, we have the frequency of resturants per zone and the frequency of crime per zone. From the data given above, there is actually an inverse relationship between the two datasets and the zones. We can see that the central zone has the most restaurants and the least amount of crime. Conversely, the North zone has the least amount of restaurants with the second to most amount of crime.\n",
    "#### Conclusion for Hypothesis 2:\n",
    "The following information above supports our hypothesis that restaurants tend to congregate around zones with less crime. \n",
    "\n",
    "In the next steps, we will compare the average rating and prices of all the restaurants in their corresponding zones. For the further analysis, we will compare the restaurant data in the Central zones with the data in the Northern zones to see if it corresponds to our hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Central zone average rating:\",restaurants_df.rating[restaurants_df.npc_zones == 'CENTRAL'].mean())\n",
    "print(\"East zone average rating:\",restaurants_df.rating[restaurants_df.npc_zones == 'EAST'].mean())\n",
    "print(\"North zone average rating:\",restaurants_df.rating[restaurants_df.npc_zones == 'NORTH'].mean())\n",
    "print(\"West zone average rating:\",restaurants_df.rating[restaurants_df.npc_zones == 'WEST'].mean())\n",
    "\n",
    "counts = pd.crosstab(restaurants_df.rating, restaurants_df.npc_zones)\n",
    "joint = counts / counts.sum().sum()\n",
    "sns.heatmap(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Central zone average price:\",restaurants_df.price_value[restaurants_df.npc_zones == 'CENTRAL'].mean())\n",
    "print(\"East zone average price:\",restaurants_df.price_value[restaurants_df.npc_zones == 'EAST'].mean())\n",
    "print(\"North zone average price:\",restaurants_df.price_value[restaurants_df.npc_zones == 'NORTH'].mean())\n",
    "print(\"West zone average price:\",restaurants_df.price_value[restaurants_df.npc_zones == 'WEST'].mean())\n",
    "\n",
    "counts = pd.crosstab(restaurants_df.price_value, restaurants_df.npc_zones)\n",
    "joint = counts / counts.sum().sum()\n",
    "sns.heatmap(joint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24fRMKkZgc1_"
   },
   "source": [
    "We can see that the Central zone has the least average rating with the highest price point and the North zone has the second highest rating to the lowest average price.\n",
    "\n",
    "#### Conclusion for Hypothesis 1:\n",
    "With that, we can conclude that an unpopular restaurant with a high price point is less likely to have crime reports in that zone. Inversely, we can also say that a lower priced, popular restaurant is more likely to be in a crime-ridden zone. This goes against our hypothesis that higher rated and higher priced restaurants have lower crime rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yelp Analysis\n",
    "Analyzing our Yelp data, we want to see if there is any correlation between the numerical values. We are looking for the following:\n",
    "1. Does the location of the business affect ratings and price?\n",
    "2. How doe ratings, price, and number of reviews affect each other?\n",
    "\n",
    "We hypothesize that more reviews mean a lower rating and lower price due to popularity (people want to get more for their money). This most likely reflects on an area of higher crime rates.\n",
    "\n",
    "We converted the ratings (based on Yelp, which is reflected by dollar sign quantity) to numbers 0-4, where 0 is a NaN and 4 is four dollar signs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combineModel = LinearRegression()\n",
    "combineModel.fit(\n",
    "    X=yelp_train[[\"zip_code\"]],\n",
    "    y=yelp_train[[\"rating\", \"review_count\"]]\n",
    ")\n",
    "combineModel.predict(\n",
    "    X=yelp_test[[\"zip_code\"]]\n",
    ")\n",
    "print(\"Predicting average rating and review count based on 92507 zip code, respectively:\\n\", combineModel.predict([[92507]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the 92507 zip code since it's more common around UCR, we can see that most restaurants average at a 3.9 rating, as well as a whole 238-239 review counts. We do this by training the acquired data on each measured/input parameter, then predicting based on our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combineModel = LinearRegression()\n",
    "combineModel.fit(\n",
    "    X=yelp_train[[\"rating\"]],\n",
    "    y=yelp_train[[\"price\", \"review_count\"]]\n",
    ")\n",
    "combineModel.predict(\n",
    "    X=yelp_test[[\"rating\"]]\n",
    ")\n",
    "print(\"Predictions for price/review count respectively, based on all ratings:\\n\")\n",
    "print(\"1.0: \", combineModel.predict([[1.0]]))\n",
    "print(\"1.5: \", combineModel.predict([[1.5]]))\n",
    "print(\"2.0: \", combineModel.predict([[2.0]]))\n",
    "print(\"2.5: \", combineModel.predict([[2.5]]))\n",
    "print(\"3.0: \", combineModel.predict([[3.0]]))\n",
    "print(\"3.5: \", combineModel.predict([[3.5]]))\n",
    "print(\"4.0: \", combineModel.predict([[4.0]]))\n",
    "print(\"4.5: \", combineModel.predict([[4.5]]))\n",
    "print(\"5.0: \", combineModel.predict([[5.0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting our prices and review counts, it seems that 1-star restaurants have the most reviews. However, the cheapest restaurants have 4-star ratings! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combineModel = LinearRegression()\n",
    "combineModel.fit(\n",
    "    X=yelp_train[[\"price\"]],\n",
    "    y=yelp_train[[\"rating\", \"review_count\"]]\n",
    ")\n",
    "combineModel.predict(\n",
    "    X=yelp_test[[\"price\"]]\n",
    ")\n",
    "print(\"Predictions for rating/review count respectively, based on all prices:\\n\")\n",
    "print(\"NaN prices: \", combineModel.predict([[0]]))\n",
    "print(\"$: \", combineModel.predict([[1]]))\n",
    "print(\"$$: \", combineModel.predict([[2]]))\n",
    "print(\"$$$: \", combineModel.predict([[3]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suprisingly, our rating goes down the more expensive our restaurant gets. We also observe that the number of reviews go up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion for Hypothesis 3:\n",
    "\n",
    "As a total analysis, we can say our data is concentrated around the 92500's zip code for Riverside County. Addressing our hypothesis, a lower rating does NOT alaways necessarily mean a lower price, as reflected in our two ML models above. A lower rating can guarantee two possible things however: the restaurant is more popular, or people tend to write more reviews for a bad experience than a good one. Since our 1-star restaurants got the most reviews and the 3-4-star restaurants got the lowest prices, it could be the latter. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
